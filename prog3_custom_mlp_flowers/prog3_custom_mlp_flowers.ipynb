{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8cf0e0",
   "metadata": {},
   "source": [
    "# CPSC320: Program 3 - Custom MLP Model for Flower Classification\n",
    "In this assignment, you need to build a Custom MultiLayer Perceptron (MLP) model using **tensorflow Keras** to classify images of flowers. You will utilize data augmentation and ImageDataGenerator to preprocess the images, followed by training a custom MLP model.\n",
    "\n",
    "**Note**:  The purpose of this project is to learn how to write custom loss, layer, model, and training loop on your own. This is not about improving prediction accuracy.\n",
    "\n",
    "**Important**: The notebook you will submit must be the one you have RUN all the cells (DO NOT CLEAR OUTPUTS OF ALL CELLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa8c293-be0d-45ef-a616-10e1a98462a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow and Keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94f655-47b1-4fac-9f08-0c03a6e1f058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22f26463",
   "metadata": {},
   "source": [
    "## 1: Data Preparation and Augmentation\n",
    "We'll use the ImageDataGenerator class to augment our training data and rescale the images. Data augmentation helps in increasing the diversity of the training data, which helps in reducing overfitting.\n",
    "\n",
    "**Note**: The assumption for constructing image_data_generator is that the flower dataset is in the **parent directory**. You may have to modify the script if your data folder resides in a different location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab76c9f-0612-4757-8929-7dde9e7d1683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerators for training data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                    rotation_range=20,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "# create validation generator with rescale, no augmentation\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b99aa0-770a-4e2e-9238-ae22cd84a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3456 images belonging to 5 classes.\n",
      "Found 865 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../flowers_train_validation/train',  # This is the target directory\n",
    "    target_size=(150, 150),  # All images will be resized to 150x150\n",
    "    batch_size=128,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '../flowers_train_validation/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444c80e-b26a-4095-b8f7-b66fd7466343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3815e35c",
   "metadata": {},
   "source": [
    "## 2: Building the Custom MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10dcea6-9beb-4a55-a42a-f4f0131fdefa",
   "metadata": {},
   "source": [
    "### 2.1 Custom Categorical Crossentropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5234a089-bf84-4556-8ecb-486489eb01e3",
   "metadata": {},
   "source": [
    "**Task 1: Defining Custom Categorical CrossEntropy Loss**\n",
    "\n",
    "The categorical cross-entropy formula is:\n",
    "$$L = - \\sum_{i=1}^{N} y_i \\log(\\hat{y_i})$$\n",
    "Where:\n",
    "- $N$ is the number of classes.\n",
    "- $y_i$ is the true label (one-hot encoded, 1 for the correct class, and 0 for the others).\n",
    "- $\\hat{y_i}$ is the predicted probability for the corresponding class (output of a `softmax`).\n",
    "\n",
    "For each sample, you will\n",
    "- Multiply with One-Hot Labels: Multiply the logarithm of the predictions with the corresponding one-hot encoded labels (y_true), so only the correct class’s prediction contributes to the loss.\n",
    "- Sum the Results: Sum the result of the above operation across all classes for each sample.\n",
    "\n",
    "In addition, you will also need to average the loss across all samples in the batch (if working with batches).\n",
    "\n",
    "**Additional Hints**:\n",
    "- You may first clip prediction values (y_pred) to avoid log(0) error, using **tf.clip_by_value**, with min of *1e-10* and max of *1.0*\n",
    "- you may then use elementwise matrix matrix multiplication on *y_true* and *tf.math.log(y_pred)* and sum up by applying **tf.reduce_sum** on the axis = -1\n",
    "- Finally you will **tf.reduce_mean** get the average for all samples in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06916529-4a3a-4a2a-b8ae-d7bac531a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom categorical entropy loss function\n",
    "def my_categorical_crossentropy(y_true, y_pred):\n",
    "\n",
    "    # Clip prediction values to avoid log(0) error\n",
    "    pass\n",
    "\n",
    "    \n",
    "    # Compute the categorical cross-entropy loss\n",
    "    pass\n",
    "\n",
    "    \n",
    "    # Return the mean loss over the batch\n",
    "    \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8722e09-26ae-4619-be73-2529065cc8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom categorical entropy loss:  tf.Tensor(0.31903753, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Define y_true (one-hot encoded labels) and y_pred (predicted probabilities)\n",
    "y_true = np.array([\n",
    "    [1, 0, 0, 0, 0],  # Class 0\n",
    "    [0, 1, 0, 0, 0],  # Class 1\n",
    "    [0, 0, 0, 1, 0]   # Class 3\n",
    "])\n",
    "\n",
    "y_pred = np.array([\n",
    "    [0.8, 0.0, 0.1, 0.05, 0.05],  # Model is confident about class 0\n",
    "    [0.1, 0.6, 0.1, 0.1, 0.1],    # Model is confident about class 1\n",
    "    [0.05, 0.05, 0.05, 0.8, 0.05]  # Model is confident about class 3\n",
    "])\n",
    "\n",
    "# Convert y_true and y_pred to tensors\n",
    "y_true_tensor = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "y_pred_tensor = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "# Compute the custom loss\n",
    "loss = my_categorical_crossentropy(y_true_tensor, y_pred_tensor)\n",
    "\n",
    "# Run the computation in a TensorFlow session\n",
    "print(\"Custom categorical entropy loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859e923-e025-42f8-8bd6-cf555efb3ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "508632c8-af34-41a3-91b1-36e4b61f4531",
   "metadata": {},
   "source": [
    "### 2.2 Custom Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e023d8-78c1-4b38-85e2-d623681b7a5e",
   "metadata": {},
   "source": [
    "### 2.2.1 MyFlatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6157a812-e0ad-468d-ba03-42e6a98fefe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Flatten layer\n",
    "class MyFlatten(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyFlatten, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Flatten the input\n",
    "        return tf.reshape(inputs, [inputs.shape[0], -1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # The output shape is (batch_size, flattened_dims)\n",
    "        # Calculate the product of all dimensions except the batch size (input_shape[0])\n",
    "        flatten_dim = 1\n",
    "        for dim in input_shape[1:]:\n",
    "            if dim is not None:\n",
    "                flatten_dim *= dim\n",
    "            else:\n",
    "                # If any dimension is None, return None (because we cannot calculate the product statically)\n",
    "                return (input_shape[0], None)\n",
    "        \n",
    "        return (input_shape[0], flatten_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "813a0e17-b0a6-4026-a493-74a9faafc8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1, 3, 3)\n",
      "Flattened output: [[1. 2. 3. 4. 5. 6. 7. 8. 9.]]\n",
      "Flattened output shape: (1, 9)\n"
     ]
    }
   ],
   "source": [
    "# Example of input with size (3, 3)\n",
    "input_data = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)\n",
    "\n",
    "# Reshape input_data to add batch dimension (batch_size, 3, 3)\n",
    "input_data = tf.expand_dims(input_data, axis=0)  # Adding batch size of 1, so shape is (1, 3, 3)\n",
    "\n",
    "# Instantiate and apply the custom flatten layer\n",
    "flatten_layer = MyFlatten()\n",
    "flattened_output = flatten_layer(input_data)\n",
    "\n",
    "# Print the result\n",
    "print(\"Input shape:\", input_data.shape)\n",
    "print(\"Flattened output:\", flattened_output.numpy())\n",
    "print(\"Flattened output shape:\", flattened_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff34ea7-491e-4a5d-8ea3-5687cbc0df6c",
   "metadata": {},
   "source": [
    "### 2.2.2 MyDense Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbe96d0-9586-49c5-acd2-c11541752616",
   "metadata": {},
   "source": [
    "**Task 2: Defining Custom Dense Layer supporting activation**:\n",
    "\n",
    "You need to implement custom MyDense Layer class. In particular, you will implement the following functions:\n",
    "- **init()**: initialize units and activations\n",
    "- **build()**: initialize weights and biases\n",
    "- **call()**: forward pass\n",
    "- **compute_output_shape()**: define output shape of the layer. It is always (batch_size, units)\n",
    "\n",
    "**Hints**:\n",
    "- You may refer to the script of *05_custom_layer_dense_with_activation.ipynb*\n",
    "- You may refer to the *compute_output_shape()* in the above *MyFlatten* class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc52aa2f-9d34-45ae-9ba0-0e98ed9da29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, activation=None):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        pass    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72528333-5c17-4574-9226-df11e07e4906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7850ff4-e089-48bd-a1b6-0908877ed4d3",
   "metadata": {},
   "source": [
    "### 2.3 Custom Model using Subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa3145-961f-4704-bcee-04e40eecb270",
   "metadata": {},
   "source": [
    "**Task 3: Defining Custom Model for Flower Prediction**:\n",
    "\n",
    "You need to implement custom MyDense Layer class. In particular, you will implement the following functions:\n",
    "- **init()**: create instances of layers (it is own decsions to define dense layers, but you must use custom **MyFlatten** and **MyDense** layeres not the keras layers)\n",
    "- **call()**: forward pass\n",
    "\n",
    "**Hints**:\n",
    "- You may refere to the scripts of *05_custom_model_wide_deep.ipynb* and \"05_custom_model_resnet.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68e8ea53-c726-4342-93f2-cf2c25a59add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model class\n",
    "class MyFlowerModel(tf.keras.models.Model):\n",
    "    def __init__(self, num_classes):\n",
    "      pass\n",
    "\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "       pass\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd036a70-5574-4943-8543-4ff83351cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyFlowerModel(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27e201-aa8b-40d1-b7cb-5c9b04caefaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "880c2a92-90a8-4a89-8d2a-e793ca3d8127",
   "metadata": {},
   "source": [
    "## 3. Custom Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca5f1e-7345-429a-bc46-94abc2519c10",
   "metadata": {},
   "source": [
    "### 3.1 Create instances for Optimizer and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34279c1-5b81-49f9-bf9e-824b3727f4cc",
   "metadata": {},
   "source": [
    "**Task 4: Create instances for optimizer and loss** \n",
    "\n",
    "- Choose `adam` optimizer and\n",
    "- Choose your custom categorical crossentropy loss (make sure it is **your custom loss**, not from keras)\n",
    "\n",
    "**Hints**:\n",
    "- You may refer to the script of *06_custom_training_categorical.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0250a53-27e1-46a4-a135-63df0e7ff133",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = None\n",
    "loss_object = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53793419-dab8-4451-b64d-c77961a0d3be",
   "metadata": {},
   "source": [
    "### 3.2 Define Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea393ee-620b-49f8-b7b1-a93573b5d60d",
   "metadata": {},
   "source": [
    "**Task 5: Create instances for metrics (both train and validation)** \n",
    "\n",
    "- Using `CategoricalAccuracy`defined in `tf.keras.metrics`\n",
    "\n",
    "**Hints**:\n",
    "- You may refer to the script of *06_custom_training_categorical.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "206e2ff3-4e37-4986-8596-455fe4118a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_metric = None\n",
    "val_acc_metric = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177249f-64e8-478a-9e34-80a3c7dbca6d",
   "metadata": {},
   "source": [
    "### 3.3 Custom Training Loop\n",
    "\n",
    "The core of training is using the model to calculate the logits on specific set of inputs and compute loss (in this case **categorical crossentropy**) by comparing the predicted outputs to the true outputs. You then update the trainable weights using the optimizer algorithm chosen. Optimizer algorithm requires your computed loss and partial derivatives of loss with respect to each of the trainable weights to make updates to the same.\n",
    "\n",
    "You use gradient tape to calculate the gradients and then update the model trainable weights using the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83851422-c634-4748-8401-360fe6b0132a",
   "metadata": {},
   "source": [
    "#### 3.3.1. Gradient Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb3f3a-3b24-44ea-8cbe-d60b6b289a92",
   "metadata": {},
   "source": [
    "**Task 6: Apply gradients on optimizer** \n",
    "\n",
    "You will define a function that accepts the inputs of:\n",
    "- *optimizer*: your optimizer used to optimize the model paramenters\n",
    "- *model*: your custom flower model\n",
    "- *x*: input training x\n",
    "- *y*: input training y\n",
    "\n",
    "The function will use tensorflow's gradientTape to calculate the gradients and then optimize the parameters through optimizer. The function will return logits (model's predicted values) and loss_value (calculated by the loss function).\n",
    "\n",
    "**Hints**:\n",
    "- You may refer to the script of *06_custom_training_categorical.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0918a1ca-46ec-4dab-9d0d-aff690675ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradient(optimizer, model, x, y):\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d99e229-8823-4a69-9905-9c1c1fe3c639",
   "metadata": {},
   "source": [
    "### 3.3.2 Define a Training for Each Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c22ad5-c67d-4f86-94fd-efbfb1c34747",
   "metadata": {},
   "source": [
    "**Task 7: train_data_for_one_epoch()** \n",
    "\n",
    "This function performs training during one epoch. You run through all batches of training data in each epoch to make updates to trainable weights using your previous function. You will aso call update_state on your metrics to accumulate the value of your metrics.\n",
    "You will display a progress bar to indicate completion of training in each epoch (use **tqdm** for displaying the progress bar).\n",
    "\n",
    "**Hints**: \n",
    "\n",
    "You can use the function from *06_custom_training_categorical.ipynb*. But make sure you need to modify the script so that it can be run for our dataset. In particular, you will need to:\n",
    "- Change **enumerate(train)** to  **enumerate(train_generator)**, due to the fact we use **imageDataGenerator** not **tfds**\n",
    "- Add **STEPS= train_generator.samples // train_generator.batch_size** before the loop (needed for stopping the generator)\n",
    "- When defining **pbar=tqdm(total=STEP,....)** not **pbar = tqdm(total=len(list(enumerate(train))),....)**\n",
    "- Stop the loop after reaching the number of STEPS. i.e. add the statements at the end in the loop: **if step >= STEPs - 1: break**.  (*Note*: generators like train_generator in Keras/TensorFlow can yield an infinite number of batches. They do not automatically stop after one epoch, unlike datasets defined with a finite number of samples.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a92510b7-5120-4da8-b2be-1f6d65e5287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_for_one_epoch():\n",
    "    losses = []\n",
    "\n",
    "    pass\n",
    "\n",
    "    \n",
    "    return losses    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dbd1cf-b2c4-4fc8-8c20-9585e68f4af3",
   "metadata": {},
   "source": [
    "#### 3.3.3 Perform Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829d450-1d78-45ab-9cc1-9c503d369c49",
   "metadata": {},
   "source": [
    "**Task 8: perform_validation()** \n",
    "\n",
    "**Hints**: \n",
    "You can use the function from *06_custom_training_categorical.ipynb*. But make sure you need to modify the script so that it can be run for our dataset. In particular, you will need to:\n",
    "- Change **enumerate(test)** to  **enumerate(validation_generator)**, due to the fact we use **imageDataGenerator** not **tfds**\n",
    "- Add **STEPS= validation_generator.samples // validation_generator.batch_size** before the loop (needed for stopping the generator)\n",
    "- Stop the loop after reaching the number of STEPS. i.e. add the statements at the end in the loop: **if step >= STEPs - 1: break**.  (*Note*: same logic as above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "606a92c4-a689-42e2-aca0-ef1b836ed387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_validation():\n",
    "    losses = []\n",
    "\n",
    "    pass\n",
    "\n",
    "    \n",
    "    return losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe82b4-ef74-4805-bc18-4e39aca4ea82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1701eb15-0c0c-4dc3-b338-2e77c5296768",
   "metadata": {},
   "source": [
    "### 3.3.4 Model fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a44fb1ad-c419-4db7-a1f1-ba71ea99704f",
   "metadata": {},
   "source": [
    "**Task 9:  Perform model fit using training Loops** \n",
    "\n",
    "Now, you define the training loop that runs through the training samples repeatedly over a fixed number of epochs. Here you combine the functions you built earlier to establish the following flow:\n",
    "1. Perform training over all batches of training data.\n",
    "2. Get values of metrics.\n",
    "3. Perform validation to calculate loss and update validation metrics on test data.\n",
    "4. Reset the metrics at the end of epoch.\n",
    "5. Display statistics at the end of each epoch.\n",
    "\n",
    "**Note** : You also calculate the training and validation losses for the whole epoch at the end of the epoch.\n",
    "\n",
    "**Hints**: \n",
    "You can use the function from *06_custom_training_categorical.ipynb*. But make sure you need to modify the script so that progress print out will be same as the one I provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acda3eec-e22f-4b33-b9fe-6f2be469e334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 27: 1.7571: 100%|██████████| 27/27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train_loss: 5.1289  Val_Loss: 1.9641, Train_acc: 0.2390, Val_acc 0.2743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 27: 1.3572: 100%|██████████| 27/27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: Train_loss: 1.5609  Val_Loss: 1.3459, Train_acc: 0.3287, Val_acc 0.4070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 27: 1.4126: 100%|██████████| 27/27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: Train_loss: 1.4215  Val_Loss: 1.2855, Train_acc: 0.3776, Val_acc 0.4406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 27: 1.4313: 100%|██████████| 27/27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: Train_loss: 1.3887  Val_Loss: 1.2744, Train_acc: 0.3981, Val_acc 0.4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 27: 1.3546: 100%|██████████| 27/27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: Train_loss: 1.3623  Val_Loss: 1.2374, Train_acc: 0.4135, Val_acc 0.4358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 27: 1.2173: 100%|██████████| 27/27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: Train_loss: 1.3442  Val_Loss: 1.2575, Train_acc: 0.4109, Val_acc 0.4502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 27: 1.3171: 100%|██████████| 27/27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: Train_loss: 1.3316  Val_Loss: 1.2254, Train_acc: 0.4146, Val_acc 0.4646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 27: 1.3213: 100%|██████████| 27/27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: Train_loss: 1.3042  Val_Loss: 1.3270, Train_acc: 0.4285, Val_acc 0.4058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 27: 1.1617: 100%|██████████| 27/27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: Train_loss: 1.3142  Val_Loss: 1.2105, Train_acc: 0.4256, Val_acc 0.4850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 27: 1.2903: 100%|██████████| 27/27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: Train_loss: 1.2985  Val_Loss: 1.2305, Train_acc: 0.4317, Val_acc 0.4550\n"
     ]
    }
   ],
   "source": [
    "# your model fitting\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216cbf95-d9bb-46a4-98e6-b98f45478319",
   "metadata": {},
   "source": [
    "**Task 10: Model Summary** \n",
    "\n",
    "Print out your model summary, your model may not look mine depending on how you define your model, but must show the followings:\n",
    "- Layer types (MyFlatten, not Keras.Flatten, MyDense, not keras.Dense)\n",
    "- Output shapes (batch size, units)\n",
    "- Parameters (based on fully connected neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "efd16d3f-9cdb-4564-8b85-3a71e61eea6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_flower_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_flower_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ my_flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyFlatten</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67500</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyDense</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,500,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyDense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyDense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">755</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ my_flatten_1 (\u001b[38;5;33mMyFlatten\u001b[0m)        │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m67500\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my_dense (\u001b[38;5;33mMyDense\u001b[0m)              │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m200\u001b[0m)             │    \u001b[38;5;34m13,500,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my_dense_1 (\u001b[38;5;33mMyDense\u001b[0m)            │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │        \u001b[38;5;34m30,150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my_dense_2 (\u001b[38;5;33mMyDense\u001b[0m)            │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m5\u001b[0m)               │           \u001b[38;5;34m755\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,531,105</span> (51.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,531,105\u001b[0m (51.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,531,105</span> (51.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,531,105\u001b[0m (51.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your model summary\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
